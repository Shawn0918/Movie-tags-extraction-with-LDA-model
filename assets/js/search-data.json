{
  
    
        "post0": {
            "title": "üé¨ Movie Tags Extraction with LDA Model",
            "content": "Introduction . If you are a movie fan, you might notice that in most movie recommendation websites, apart from the category the movie is classified in, there&#39;s usually some descriptive tags attached to each movie. The tags can describe the character in the movie, such as The Dark Knight which has the &quot;superhero&quot; tag, or an element in the movie, like the tag &quot;dinosaur&quot; on Jurassic World. Sometimes, the tag could even be the name of a movie star, such as &quot;Leonardo&quot; on Titanic. From a perspective of a movie fan, it&#39;s undoubtedly that these tags display the attractive points of the movie more vividly than the tedious classifications &quot;Classic movies&quot; and &quot;Action movies&quot;. Therefore, people began to extract tags from the content of the films, utilizing machine learning and natural language processing methods. . This project is aimed to explore a Netflix movies dataset, to gain some insights about movie industry and make an attempt to extract some tags from the movie descriptions. . Methods . Dataset Introduction . This notebook includes a movie dataset from https://www.kaggle.com/datasets/shivamb/netflix-shows, which consists of listings of all the movies and TV-shows available on Netflix, along with details such as - cast, directors, ratings, release year, duration, etc. . Specifically, here&#39;s the meaning of each column in the dataset: . show_id: Unique ID for every Movie / Tv Show type: Identifier - A Movie or TV Show title: Title of the Movie / Tv Show director: Director of the Movie cast: Actors involved in the movie / show country: Country where the movie / show was produced date_added: Date it was added on Netflix release_year: Actual Release year of the move / show rating: TV Rating of the movie / show duration: Total Duration - in minutes or number of seasons listed_in: Genere description: The summary description . LDA model . Latent Dirichlet allocation (LDA) is a widey used topic-generating model. The model can identify the representative topics underlying a document collection or a corpus. This model produces topics based on bag-of-word feature, that each document is represented as a vector, in which every word corresponds to an id and its appearing frequency in the document. When producing the topics, The model samples a document-specific multinomial distribution over topics from Dirichlet distribution, and samples the word in the document from the corresponding multinomial distribution. . &#128202; Exploratory Analysis &amp; Results . 1. &#127909; Data Preprocessing . Import the libraries . import pandas as pd import nltk import matplotlib.pyplot as plt import ipywidgets import gensim import re import wordcloud import altair from nltk.tokenize import word_tokenize, sent_tokenize from nltk.corpus import stopwords from string import punctuation from nltk.stem.porter import PorterStemmer from gensim import corpora, models . Import the dataset and create a dataframe for movies . df = pd.read_csv(&quot;data/netflix_titles.csv&quot;) movies = df[df[&quot;type&quot;]==&quot;Movie&quot;] movies.index = range(len(movies)) . Column information . &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; RangeIndex: 6131 entries, 0 to 6130 Data columns (total 12 columns): # Column Non-Null Count Dtype -- -- 0 show_id 6131 non-null object 1 type 6131 non-null object 2 title 6131 non-null object 3 director 5943 non-null object 4 cast 5656 non-null object 5 country 5691 non-null object 6 date_added 6131 non-null object 7 release_year 6131 non-null int64 8 rating 6129 non-null object 9 duration 6128 non-null object 10 listed_in 6131 non-null object 11 description 6131 non-null object dtypes: int64(1), object(11) memory usage: 574.9+ KB . Missing values visualization . &lt;AxesSubplot:&gt; . üçøÔ∏èComment: . The missing values are distributed in columns &quot;director&quot;, &quot;cast&quot;, &quot;country&quot; and &quot;duration&quot;. | . Sample rows . show_id type title director cast country date_added release_year rating duration listed_in description . 5581 s8135 | Movie | Susanne Bartsch: On Top | Anthony Caronna, Alexander Smith | Susanne Bartsch | United States | December 10, 2018 | 2017 | TV-MA | 86 min | Documentaries, LGBTQ Movies | Beyond her larger-than-life persona, this docu... | . 836 s1263 | Movie | Ginny &amp; Georgia - The Afterparty | NaN | David Spade, London Hughes, Fortune Feimster, ... | NaN | February 26, 2021 | 2021 | TV-MA | 35 min | Comedies, Dramas | Cast members of the hit Netflix show join the ... | . 5120 s7547 | Movie | My Sister&#39;s Keeper | Nick Cassavetes | Cameron Diaz, Abigail Breslin, Alec Baldwin, J... | United States | September 1, 2019 | 2009 | PG-13 | 109 min | Dramas | A former defense attorney finds herself back i... | . 2894 s4544 | Movie | Monty Python Conquers America | Will Yapp | Graham Chapman, Eric Idle, Terry Jones, Michae... | NaN | October 2, 2018 | 2008 | TV-MA | 55 min | Documentaries | Follow the evolution of the British sketch com... | . 3913 s6021 | Movie | 5CM | Rizal Mantovani | Herjunot Ali, Raline Shah, Fedi Nuril, Pevita ... | Indonesia | September 28, 2018 | 2012 | TV-14 | 126 min | Dramas, International Movies | Five friends embark on a mission to climb the ... | . üçøÔ∏èComment: . Based on the information in these rows, I converted the values in &quot;duration&quot; column into integers and the values in &quot;date_added&quot; column into date, to prepare them for plotting in the next section. | . 2. &#128200;Exploratory Analysis . Visualization 1 . üçøÔ∏èComment: . The histogram shows that most movies on Netflix are about 100 minutes. The longest movie contained in this dataframe is about to reach 300 minutes, nearly 5 hours. | . Visualization 2 . üçøÔ∏èComment: . Most movies included in the dataframe are released in recent 10 years. | . Visualization 3 . üçøÔ∏èComments: . The duration of all movies shot in 1940s are below 100 minutes, while many movies released after 1960 are over 100 minutes. | There&#39;s an increase of movies duration in 1960s, that most movies&#39; duration surpass 100 minutes and the longest one even reaches 200 minutes. | The short movies didn&#39;t quit the stage. In recent 10 years, there are still many movies with the duration below 50 minutes. | . Visualization 4 . üçøÔ∏èComment: . Few films produced in mainland China are available on Netflix. The number of movies on Netflix produced in Hong Kong even surpasses that of mainland China. | . Visualization 5 . üçøÔ∏èComment: . There are many renowned directors such as &quot;Christopher Nolan&quot; and &quot;Alfred Hitchcock&quot; who have directed many well-known movies are not included, from which it&#39;s reasonable to infer that many popular movies aren&#39;t available on Netflix or they didn&#39;t be collected by this dataset. | . Visualization 6 . üçøÔ∏èComments: . Apart from those movies that have been clearly categorized, there&#39;s a type named &quot;Movies&quot;, which suggests that movies in this type are not categorized due to some reason. We will examine the content of these movies and determine how should they be classified. | There aren&#39;t clear boundary between some of the categories, which means a movie can have multiple categories. The dim boundary may confuse the viewers and thus it&#39;s necessary to give these movies representative tags. | Through the names of some categories we can roughly predict the content of the movies. For instance, Faith &amp; Spirituality movies may contain a lot of religious elements. This provides the possibility for the afterwards tag prediction task based on the descriptions of movies. | . 3. &#127991; Tags Extraction . In this section, I used the LDA model to analyze the descriptions of a certain category of movie and extract the keywords to represent the category. Specifically, I first used nltk to preprocess the description texts. Then I made a dictionary and a corpus for the tokenized and stemmed words. Finally, I used the LDA model to extract the keywords depending on appearing frequency and drew the word cloud graph to visualize the result. . Create a list to store the descriptions of movies from different categories . DescByTypes = [] for i in range(len(categories)): DescByTypes.append([movies.loc[x,&#39;description&#39;] for x in range(len(movies)) if categories[i] in movies.loc[x,&#39;listed_in&#39;].split(&#39;, &#39;)]) . Create the list for documentary descriptions . Documentaries = DescByTypes[0] . Tokenize the document . myStopWords = list(punctuation) + stopwords.words(&#39;english&#39;) Docu = [] for i in Documentaries: Docu.append([w for w in word_tokenize(i.lower()) if w not in myStopWords]) . Stem the words . p_stemmer = PorterStemmer() Docu_stemmed = [] for i in Docu: Docu_stemmed.append([p_stemmer.stem(w) for w in i]) . Create a dictionary . dictionary = corpora.Dictionary(Docu_stemmed) dictionary.filter_extremes(no_below=5, no_above=0.5) . print(dictionary.token2id) . {&#39;comic&#39;: 0, &#39;death&#39;: 1, &#39;end&#39;: 2, &#39;face&#39;: 3, &#39;father&#39;: 4, &#39;filmmak&#39;: 5, &#39;help&#39;: 6, &#39;life&#39;: 7, &#39;stage&#39;: 8, &#39;way&#39;: 9, &#39;becam&#39;: 10, &#39;close&#39;: 11, &#39;document&#39;: 12, &#39;escap&#39;: 13, &#39;hitler&#39;: 14, &#39;presid&#39;: 15, &#39;reveal&#39;: 16, &#39;spain&#39;: 17, &#39;world&#39;: 18, &#34;&#39;s&#34;: 19, &#39;big&#39;: 20, &#39;childhood&#39;: 21, &#39;dream&#39;: 22, &#39;live&#39;: 23, &#39;love&#39;: 24, &#39;rescu&#39;: 25, &#39;train&#39;: 26, &#39;archiv&#39;: 27, &#39;champion&#39;: 28, &#39;documentari&#39;: 29, &#39;footag&#39;: 30, &#39;interview&#39;: 31, &#39;intim&#39;: 32, &#39;michael&#39;: 33, &#39;portrait&#39;: 34, &#39;trace&#39;: 35, &#39;bond&#39;: 36, &#39;extraordinari&#39;: 37, &#39;ideal&#39;: 38, &#39;meet&#39;: 39, &#39;tragic&#39;: 40, &#39;captur&#39;: 41, &#39;killer&#39;: 42, &#39;mother&#39;: 43, &#39;polic&#39;: 44, &#39;two&#39;: 45, &#39;victim&#39;: 46, &#39;women&#39;: 47, &#39;work&#39;: 48, &#39;chart&#39;: 49, &#39;legendari&#39;: 50, &#39;man&#39;: 51, &#39;stori&#39;: 52, &#39;use&#39;: 53, &#39;american&#39;: 54, &#39;challeng&#39;: 55, &#39;chang&#39;: 56, &#39;continu&#39;: 57, &#39;health&#39;: 58, &#39;tradit&#39;: 59, &#39;win&#39;: 60, &#39;gener&#39;: 61, &#39;last&#39;: 62, &#39;peopl&#39;: 63, &#39;togeth&#39;: 64, &#39;cultur&#39;: 65, &#39;examin&#39;: 66, &#39;famili&#39;: 67, &#39;hip-hop&#39;: 68, &#39;perform&#39;: 69, &#39;race&#39;: 70, &#39;rap&#39;: 71, &#39;song&#39;: 72, &#39;violenc&#39;: 73, &#34;&#39;&#39;&#34;: 74, &#39;``&#39;: 75, &#39;advoc&#39;: 76, &#39;inspir&#39;: 77, &#39;intern&#39;: 78, &#39;relationship&#39;: 79, &#39;share&#39;: 80, &#39;star&#39;: 81, &#39;tour&#39;: 82, &#39;view&#39;: 83, &#39;boy&#39;: 84, &#39;run&#39;: 85, &#39;team&#39;: 86, &#39;‚Äî&#39;: 87, &#39;art&#39;: 88, &#39;battl&#39;: 89, &#39;bob&#39;: 90, &#39;busi&#39;: 91, &#39;cast&#39;: 92, &#39;empir&#39;: 93, &#39;famou&#39;: 94, &#39;joy&#39;: 95, &#39;million&#39;: 96, &#39;‚Äô&#39;: 97, &#39;becom&#39;: 98, &#39;first&#39;: 99, &#39;four&#39;: 100, &#39;river&#39;: 101, &#39;set&#39;: 102, &#39;come&#39;: 103, &#39;connect&#39;: 104, &#39;featur&#39;: 105, &#39;greatest&#39;: 106, &#39;human&#39;: 107, &#39;journey&#39;: 108, &#39;power&#39;: 109, &#39;rock&#39;: 110, &#39;embrac&#39;: 111, &#39;even&#39;: 112, &#39;olymp&#39;: 113, &#39;path&#39;: 114, &#39;road&#39;: 115, &#39;true&#39;: 116, &#39;crime&#39;: 117, &#39;narrat&#39;: 118, &#39;record&#39;: 119, &#39;seri&#39;: 120, &#39;abus&#39;: 121, &#39;martin&#39;: 122, &#39;person&#39;: 123, &#39;public&#39;: 124, &#39;girl&#39;: 125, &#39;discuss&#39;: 126, &#39;fan&#39;: 127, &#39;fight&#39;: 128, &#39;figur&#39;: 129, &#39;game&#39;: 130, &#39;legaci&#39;: 131, &#39;nba&#39;: 132, &#39;player&#39;: 133, &#39;brazilian&#39;: 134, &#39;citi&#39;: 135, &#39;crew&#39;: 136, &#39;decad&#39;: 137, &#39;film&#39;: 138, &#39;find&#39;: 139, &#39;took&#39;: 140, &#39;creat&#39;: 141, &#39;pioneer&#39;: 142, &#39;privat&#39;: 143, &#39;queen&#39;: 144, &#39;struggl&#39;: 145, &#39;commun&#39;: 146, &#39;devast&#39;: 147, &#39;movement&#39;: 148, &#39;speak&#39;: 149, &#39;survivor&#39;: 150, &#39;drug&#39;: 151, &#39;onlin&#39;: 152, &#39;career&#39;: 153, &#39;decades-long&#39;: 154, &#39;glimps&#39;: 155, &#39;delv&#39;: 156, &#39;call&#39;: 157, &#39;femal&#39;: 158, &#39;offic&#39;: 159, &#39;pay&#39;: 160, &#39;sexual&#39;: 161, &#39;album&#39;: 162, &#39;bring&#39;: 163, &#39;hit&#39;: 164, &#39;rapper&#39;: 165, &#39;camp&#39;: 166, &#39;championship&#39;: 167, &#39;compet&#39;: 168, &#39;emerg&#39;: 169, &#39;teen&#39;: 170, &#39;actress&#39;: 171, &#39;deep&#39;: 172, &#39;eye&#39;: 173, &#39;hollywood&#39;: 174, &#39;look&#39;: 175, &#39;take&#39;: 176, &#39;dive&#39;: 177, &#39;journalist&#39;: 178, &#39;mexican&#39;: 179, &#39;murder&#39;: 180, &#39;polit&#39;: 181, &#39;day&#39;: 182, &#39;follow&#39;: 183, &#39;footbal&#39;: 184, &#39;risk&#39;: 185, &#39;time&#39;: 186, &#39;around&#39;: 187, &#39;comedian&#39;: 188, &#39;men&#39;: 189, &#39;passion&#39;: 190, &#39;street&#39;: 191, &#39;final&#39;: 192, &#39;friend&#39;: 193, &#39;high&#39;: 194, &#39;school&#39;: 195, &#39;suicid&#39;: 196, &#39;creativ&#39;: 197, &#39;design&#39;: 198, &#39;director&#39;: 199, &#39;goe&#39;: 200, &#39;origin&#39;: 201, &#39;search&#39;: 202, &#39;age&#39;: 203, &#39;competit&#39;: 204, &#39;pursu&#39;: 205, &#39;sister&#39;: 206, &#39;three&#39;: 207, &#39;track&#39;: 208, &#39;truth&#39;: 209, &#39;adventur&#39;: 210, &#39;best&#39;: 211, &#39;build&#39;: 212, &#39;uniqu&#39;: 213, &#39;comedi&#39;: 214, &#39;experi&#39;: 215, &#39;free&#39;: 216, &#39;side&#39;: 217, &#39;war&#39;: 218, &#39;special&#39;: 219, &#39;chronicl&#39;: 220, &#39;larg&#39;: 221, &#39;member&#39;: 222, &#39;base&#39;: 223, &#39;divers&#39;: 224, &#39;emot&#39;: 225, &#39;five&#39;: 226, &#39;fuel&#39;: 227, &#39;young&#39;: 228, &#34;&#39;ve&#34;: 229, &#39;lead&#39;: 230, &#39;make&#39;: 231, &#39;new&#39;: 232, &#39;open&#39;: 233, &#39;scientist&#39;: 234, &#39;anim&#39;: 235, &#39;begin&#39;: 236, &#39;creator&#39;: 237, &#39;celebr&#39;: 238, &#39;home&#39;: 239, &#39;moment&#39;: 240, &#39;present&#39;: 241, &#39;showcas&#39;: 242, &#39;video&#39;: 243, &#39;crisi&#39;: 244, &#39;david&#39;: 245, &#39;earth&#39;: 246, &#39;known&#39;: 247, &#39;one&#39;: 248, &#39;prepar&#39;: 249, &#39;singer&#39;: 250, &#39;black&#39;: 251, &#39;explor&#39;: 252, &#39;quest&#39;: 253, &#39;understand&#39;: 254, &#39;univers&#39;: 255, &#39;america&#39;: 256, &#39;prison&#39;: 257, &#39;system&#39;: 258, &#39;year&#39;: 259, &#39;bomb&#39;: 260, &#39;gay&#39;: 261, &#39;london&#39;: 262, &#39;effect&#39;: 263, &#39;evolut&#39;: 264, &#39;genr&#39;: 265, &#39;activist&#39;: 266, &#39;amid&#39;: 267, &#39;controversi&#39;: 268, &#39;earli&#39;: 269, &#39;justic&#39;: 270, &#39;right&#39;: 271, &#39;endur&#39;: 272, &#39;recount&#39;: 273, &#39;club&#39;: 274, &#39;past&#39;: 275, &#39;success&#39;: 276, &#39;writer&#39;: 277, &#39;artist&#39;: 278, &#39;concert&#39;: 279, &#39;music&#39;: 280, &#39;tell&#39;: 281, &#39;discov&#39;: 282, &#39;woman&#39;: 283, &#39;camera&#39;: 284, &#39;student&#39;: 285, &#39;turn&#39;: 286, &#39;fall&#39;: 287, &#39;industri&#39;: 288, &#39;john&#39;: 289, &#39;rise&#39;: 290, &#39;1980&#39;: 291, &#39;band&#39;: 292, &#39;sound&#39;: 293, &#39;former&#39;: 294, &#39;india&#39;: 295, &#39;return&#39;: 296, &#39;profession&#39;: 297, &#39;indian&#39;: 298, &#39;product&#39;: 299, &#39;scene&#39;: 300, &#39;seen&#39;: 301, &#39;behind-the-scen&#39;: 302, &#39;provid&#39;: 303, &#39;root&#39;: 304, &#39;york&#39;: 305, &#39;talk&#39;: 306, &#39;trauma&#39;: 307, &#39;kill&#39;: 308, &#39;line&#39;: 309, &#39;media&#39;: 310, &#39;social&#39;: 311, &#39;icon&#39;: 312, &#39;memori&#39;: 313, &#39;investig&#39;: 314, &#39;research&#39;: 315, &#39;answer&#39;: 316, &#39;behind&#39;: 317, &#39;disappear&#39;: 318, &#39;mysteri&#39;: 319, &#39;expos&#39;: 320, &#39;role&#39;: 321, &#39;white&#39;: 322, &#39;complex&#39;: 323, &#39;offer&#39;: 324, &#39;beauti&#39;: 325, &#39;ident&#39;: 326, &#39;includ&#39;: 327, &#39;mean&#39;: 328, &#39;practic&#39;: 329, &#39;spiritu&#39;: 330, &#39;ii&#39;: 331, &#39;corrupt&#39;: 332, &#39;global&#39;: 333, &#39;ocean&#39;: 334, &#39;belov&#39;: 335, &#39;walk&#39;: 336, &#39;get&#39;: 337, &#39;rich&#39;: 338, &#39;top&#39;: 339, &#39;us&#39;: 340, &#39;real&#39;: 341, &#39;fashion&#39;: 342, &#39;in-depth&#39;: 343, &#39;king&#39;: 344, &#39;notori&#39;: 345, &#39;rare&#39;: 346, &#39;air&#39;: 347, &#39;hous&#39;: 348, &#39;innov&#39;: 349, &#39;brazil&#39;: 350, &#39;hero&#39;: 351, &#39;nation&#39;: 352, &#39;talent&#39;: 353, &#39;turbul&#39;: 354, &#39;mix&#39;: 355, &#39;back&#39;: 356, &#39;countri&#39;: 357, &#39;land&#39;: 358, &#39;natur&#39;: 359, &#39;ground&#39;: 360, &#39;physic&#39;: 361, &#39;question&#39;: 362, &#39;seek&#39;: 363, &#39;group&#39;: 364, &#39;start&#39;: 365, &#39;danc&#39;: 366, &#39;effort&#39;: 367, &#39;program&#39;: 368, &#39;globe&#39;: 369, &#39;visual&#39;: 370, &#39;idol&#39;: 371, &#39;italian&#39;: 372, &#39;short&#39;: 373, &#39;strength&#39;: 374, &#39;histori&#39;: 375, &#39;charact&#39;: 376, &#39;backstag&#39;: 377, &#39;basketbal&#39;: 378, &#39;determin&#39;: 379, &#39;french&#39;: 380, &#39;led&#39;: 381, &#39;whose&#39;: 382, &#39;go&#39;: 383, &#39;scienc&#39;: 384, &#39;process&#39;: 385, &#39;spark&#39;: 386, &#39;play&#39;: 387, &#39;actor&#39;: 388, &#39;ambiti&#39;: 389, &#39;six&#39;: 390, &#39;chef&#39;: 391, &#39;embark&#39;: 392, &#39;reflect&#39;: 393, &#39;restaur&#39;: 394, &#39;spotlight&#39;: 395, &#39;cours&#39;: 396, &#39;futur&#39;: 397, &#39;brown&#39;: 398, &#39;leader&#39;: 399, &#39;children&#39;: 400, &#39;forg&#39;: 401, &#39;societi&#39;: 402, &#39;throughout&#39;: 403, &#39;hope&#39;: 404, &#39;south&#39;: 405, &#39;tri&#39;: 406, &#39;need&#39;: 407, &#39;shape&#39;: 408, &#39;award-win&#39;: 409, &#39;de&#39;: 410, &#39;la&#39;: 411, &#39;attempt&#39;: 412, &#39;unearth&#39;: 413, &#39;1970&#39;: 414, &#39;strive&#39;: 415, &#39;mission&#39;: 416, &#39;save&#39;: 417, &#39;across&#39;: 418, &#39;water&#39;: 419, &#39;forc&#39;: 420, &#39;leav&#39;: 421, &#39;trip&#39;: 422, &#39;child&#39;: 423, &#39;detail&#39;: 424, &#39;daughter&#39;: 425, &#39;fail&#39;: 426, &#39;mexico&#39;: 427, &#39;join&#39;: 428, &#39;major&#39;: 429, &#39;superstar&#39;: 430, &#39;move&#39;: 431, &#39;insid&#39;: 432, &#39;influenti&#39;: 433, &#39;immigr&#39;: 434, &#39;event&#39;: 435, &#39;center&#39;: 436, &#39;differ&#39;: 437, &#39;africa&#39;: 438, &#39;african&#39;: 439, &#39;introduc&#39;: 440, &#39;combat&#39;: 441, &#39;expert&#39;: 442, &#39;may&#39;: 443, &#39;1992&#39;: 444, &#39;danger&#39;: 445, &#39;impact&#39;: 446, &#39;learn&#39;: 447, &#39;light&#39;: 448, &#39;shed&#39;: 449, &#39;pop&#39;: 450, &#39;account&#39;: 451, &#39;domin&#39;: 452, &#39;athlet&#39;: 453, &#39;elit&#39;: 454, &#39;space&#39;: 455, &#39;cup&#39;: 456, &#39;highlight&#39;: 457, &#39;fame&#39;: 458, &#39;reconstruct&#39;: 459, &#39;secret&#39;: 460, &#39;small&#39;: 461, &#39;town&#39;: 462, &#39;profil&#39;: 463, &#39;sever&#39;: 464, &#39;navig&#39;: 465, &#39;pass&#39;: 466, &#39;island&#39;: 467, &#39;book&#39;: 468, &#39;frank&#39;: 469, &#39;produc&#39;: 470, &#39;suffer&#39;: 471, &#39;travel&#39;: 472, &#39;doctor&#39;: 473, &#39;surviv&#39;: 474, &#39;sport&#39;: 475, &#39;candid&#39;: 476, &#39;biggest&#39;: 477, &#39;compani&#39;: 478, &#39;tale&#39;: 479, &#39;other&#39;: 480, &#39;adult&#39;: 481, &#39;extrem&#39;: 482, &#39;musician&#39;: 483, &#39;jewish&#39;: 484, &#39;protest&#39;: 485, &#39;beyond&#39;: 486, &#39;photograph&#39;: 487, &#39;wave&#39;: 488, &#39;statu&#39;: 489, &#39;legend&#39;: 490, &#39;defin&#39;: 491, &#39;eleph&#39;: 492, &#39;govern&#39;: 493, &#39;driver&#39;: 494, &#39;racial&#39;: 495, &#39;break&#39;: 496, &#39;robert&#39;: 497, &#39;brother&#39;: 498, &#39;influenc&#39;: 499, &#39;ancient&#39;: 500, &#39;realiti&#39;: 501, &#39;entrepreneur&#39;: 502, &#39;farmer&#39;: 503, &#39;founder&#39;: 504, &#39;‚Äì&#39;: 505, &#39;civilian&#39;: 506, &#39;veteran&#39;: 507, &#39;show&#39;: 508, &#39;recal&#39;: 509, &#39;act&#39;: 510, &#39;shock&#39;: 511, &#39;environment&#39;: 512, &#39;achiev&#39;: 513, &#39;modern&#39;: 514, &#39;anniversari&#39;: 515, &#39;nazi&#39;: 516, &#39;benefit&#39;: 517, &#39;heal&#39;: 518, &#39;left&#39;: 519, &#39;chines&#39;: 520, &#39;clash&#39;: 521, &#39;surround&#39;: 522, &#39;basebal&#39;: 523, &#39;scandal&#39;: 524, &#39;name&#39;: 525, &#39;u.s.&#39;: 526, &#39;unpreced&#39;: 527, &#39;long&#39;: 528, &#39;soccer&#39;: 529, &#39;cancer&#39;: 530, &#39;civil&#39;: 531, &#39;brutal&#39;: 532, &#39;ill&#39;: 533, &#39;roll&#39;: 534, &#39;tv&#39;: 535, &#39;2012&#39;: 536, &#39;potenti&#39;: 537, &#39;sens&#39;: 538, &#39;shot&#39;: 539, &#39;histor&#39;: 540, &#39;grow&#39;: 541, &#39;worldwid&#39;: 542, &#39;execut&#39;: 543, &#39;festiv&#39;: 544, &#39;insight&#39;: 545, &#39;well&#39;: 546, &#39;wit&#39;: 547, &#39;studio&#39;: 548, &#39;test&#39;: 549, &#39;made&#39;: 550, &#39;master&#39;: 551, &#39;british&#39;: 552, &#39;case&#39;: 553, &#39;access&#39;: 554, &#39;jone&#39;: 555, &#39;campaign&#39;: 556, &#39;epic&#39;: 557, &#39;patient&#39;: 558, &#39;evid&#39;: 559, &#39;like&#39;: 560, &#39;mountain&#39;: 561, &#39;remark&#39;: 562, &#39;popular&#39;: 563, &#39;convict&#39;: 564, &#39;ride&#39;: 565, &#39;soldier&#39;: 566, &#39;wife&#39;: 567, &#39;food&#39;: 568, &#39;part&#39;: 569, &#39;teenag&#39;: 570, &#39;oper&#39;: 571, &#39;dramat&#39;: 572, &#39;daredevil&#39;: 573, &#39;form&#39;: 574, &#39;result&#39;: 575, &#39;blend&#39;: 576, &#39;classic&#39;: 577, &#39;exist&#39;: 578, &#39;dare&#39;: 579, &#39;evolv&#39;: 580, &#39;organ&#39;: 581} . . üçøÔ∏èComment: . In this dictionary, each word corresponds to an unique number. | . Make a corpus . corpus = [dictionary.doc2bow(text) for text in Docu_stemmed] . Establish the LDA model to extract keywords . ldamodel = gensim.models.ldamodel.LdaModel(corpus, num_topics=1, id2word = dictionary, passes=5, random_state=1) . output generated . ldamodel.show_topics(num_topics=1) . [(0, &#39;0.039*&#34;documentari&#34; + 0.030*&#34; &#39;s&#34; + 0.012*&#34;life&#34; + 0.010*&#34;world&#34; + 0.010*&#34;explor&#34; + 0.010*&#34;follow&#34; + 0.009*&#34;``&#34; + 0.009*&#34; &#39; &#39;&#34; + 0.009*&#34;film&#34; + 0.007*&#34;stori&#34;&#39;)] . üçøComment: . The number in front of each word is measured based on the appearing frequency of the word in the document, and can be explained as the recommendation rate to choose the word as the topic word. | Some of the words such as &quot;documentary&quot;, &quot;explore&quot;, and &quot;world&quot; accurately reflect the content of this category, which proves the feasibility of this task. | There are many punctuations and uninformative words involved in this list, so the next step is to add these strings to our stop words list to remove them from the dictionary. | . modify the stop words list . myStopWords.extend([&quot;&#39;s&quot;,&quot;&#39;&quot;,&quot;¬∑&quot;,&quot;``&quot;,&#39;&quot;&#39;,&#39;‚Äî&#39;]) . Repeat the steps above . Desc = [] for i in DescByTypes[19]: Desc.append([w for w in word_tokenize(i.lower()) if w not in myStopWords]) p_stemmer = PorterStemmer() Desc_stemmed = [] for i in Desc: Desc_stemmed.append([p_stemmer.stem(w) for w in i]) dictionary = corpora.Dictionary(Desc_stemmed) dictionary.filter_extremes(no_below=5, no_above=0.5) corpus = [dictionary.doc2bow(text) for text in Desc_stemmed] ldamodel = gensim.models.ldamodel.LdaModel(corpus, num_topics=1, id2word = dictionary, passes=5, random_state=1) fig,ax = plt.subplots() x = [] y = [] count = 0 for i in re.split(re.escape(&#39; + &#39;) + &#39;|&#39; + re.escape(&#39;*&#39;), ldamodel.print_topics(num_topics=1, num_words=20)[0][1]): if count % 2 == 0: y.insert(0,float(i)) else: x.insert(0,i) count += 1 ax.barh(x,y,height=0.5) ax.set_title(categories[19]) plt.tight_layout() plt.show() . üçøComments: . The tag words in most categories can accurately reflect the content of the movies invovled in that category, such as &quot;gay&quot;, &quot;love&quot; and &quot;teen&quot; for LGBTQ movies, &quot;murder&quot;, &quot;mystery&quot;, &quot;secret&quot; and &quot;killer&quot; for Thrillers and &quot;team&quot;, &quot;player&quot;, &quot;soccer&quot; and &quot;champion&quot; for sports movies. | By adding those punctuations into myStopWords, there are mostly meaningful words in the graphs. | The &quot;Movies&quot; category that was mentioned before might be some movies about holidays, because of the keywords &quot;friend&quot;, &quot;christma&quot; and &quot;holiday&quot; in the chart. | . Visualize the output with wordcloud graph . üçøComments: . The wordcloud graph visualizes the outcome to a more readable form. Specifically, the size of the words appeared in the graph is aligned with their appearing frequency in the document. | Though there are still several meaningless marks and some of the words are not closely related to the category, there are a bunch of useful words that can generalize the movie category. | . üåüA Little Idea: After I&#39;ve done this, it occurs to me an interesting game, which is to use mainly the words provided in the graph to form a sentence related to that category. For instance, we form a sentence related to Documentaries with the words in this graph‚Äî‚Äî&quot;Documentaries are footages about people exploring the world and telling their stories&quot;. . Conclusion . The project has successfully extracted tags from the corpus of a category of movies and has made the outcome visualized. Besides, the result manifests the feasibility to extract keywords from a set of short paragraphs that share some common features, so the methodology might be useful in the future to extract keywords from a set of comments with similarity in the topic and the sentiment. . Movie tags extraction is a promising way to increase the popularity of underestimated movies, and enables more people to enjoy the fun of watching a film that fits their appetites in the holiday. With the rapid development of data science, I believe that in the near future, not only the movies, but also the classic novel, the operas and all other forms of art will be classified and stored in a more fine-grained way, which will exposed people to art,spreading the virtues, and help establish prosperous society. . If you have any feedbacks or suggestions on how to improve my work, please let me know in the comments. . Thank you! .",
            "url": "https://shawn0918.github.io/Movie-tags-extraction-with-LDA-model/fastpages/jupyter/2022/09/01/Final-Project.html",
            "relUrl": "/fastpages/jupyter/2022/09/01/Final-Project.html",
            "date": " ‚Ä¢ Sep 1, 2022"
        }
        
    
  
    
        ,"post1": {
            "title": "Fastpages Notebook Blog Post",
            "content": "About . This notebook is a demonstration of some of capabilities of fastpages with notebooks. . With fastpages you can save your jupyter notebooks into the _notebooks folder at the root of your repository, and they will be automatically be converted to Jekyll compliant blog posts! . Front Matter . The first cell in your Jupyter Notebook or markdown blog post contains front matter. Front matter is metadata that can turn on/off options in your Notebook. It is formatted like this: . # &quot;My Title&quot; &gt; &quot;Awesome summary&quot; - toc:true- branch: master - badges: true - comments: true - author: Hamel Husain &amp; Jeremy Howard - categories: [fastpages, jupyter] . Setting toc: true will automatically generate a table of contents | Setting badges: true will automatically include GitHub and Google Colab links to your notebook. | Setting comments: true will enable commenting on your blog post, powered by utterances. | . The title and description need to be enclosed in double quotes only if they include special characters such as a colon. More details and options for front matter can be viewed on the front matter section of the README. . Markdown Shortcuts . A #hide comment at the top of any code cell will hide both the input and output of that cell in your blog post. . A #hide_input comment at the top of any code cell will only hide the input of that cell. . The comment #hide_input was used to hide the code that produced this. . put a #collapse-hide flag at the top of any cell if you want to hide that cell by default, but give the reader the option to show it: . import pandas as pd import altair as alt . . put a #collapse-show flag at the top of any cell if you want to show that cell by default, but give the reader the option to hide it: . cars = &#39;https://vega.github.io/vega-datasets/data/cars.json&#39; movies = &#39;https://vega.github.io/vega-datasets/data/movies.json&#39; sp500 = &#39;https://vega.github.io/vega-datasets/data/sp500.csv&#39; stocks = &#39;https://vega.github.io/vega-datasets/data/stocks.csv&#39; flights = &#39;https://vega.github.io/vega-datasets/data/flights-5k.json&#39; . . place a #collapse-output flag at the top of any cell if you want to put the output under a collapsable element that is closed by default, but give the reader the option to open it: . print(&#39;The comment #collapse-output was used to collapse the output of this cell by default but you can expand it.&#39;) . The comment #collapse-output was used to collapse the output of this cell by default but you can expand it. . . Interactive Charts With Altair . Charts made with Altair remain interactive. Example charts taken from this repo, specifically this notebook. . df . Title US_Gross Worldwide_Gross US_DVD_Sales Production_Budget Release_Date MPAA_Rating Running_Time_min Distributor Source Major_Genre Creative_Type Director Rotten_Tomatoes_Rating IMDB_Rating IMDB_Votes . 0 The Land Girls | 146083.0 | 146083.0 | NaN | 8000000.0 | Jun 12 1998 | R | NaN | Gramercy | None | None | None | None | NaN | 6.1 | 1071.0 | . 1 First Love, Last Rites | 10876.0 | 10876.0 | NaN | 300000.0 | Aug 07 1998 | R | NaN | Strand | None | Drama | None | None | NaN | 6.9 | 207.0 | . 2 I Married a Strange Person | 203134.0 | 203134.0 | NaN | 250000.0 | Aug 28 1998 | None | NaN | Lionsgate | None | Comedy | None | None | NaN | 6.8 | 865.0 | . 3 Let&#39;s Talk About Sex | 373615.0 | 373615.0 | NaN | 300000.0 | Sep 11 1998 | None | NaN | Fine Line | None | Comedy | None | None | 13.0 | NaN | NaN | . 4 Slam | 1009819.0 | 1087521.0 | NaN | 1000000.0 | Oct 09 1998 | R | NaN | Trimark | Original Screenplay | Drama | Contemporary Fiction | None | 62.0 | 3.4 | 165.0 | . ... ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | . 3196 Zack and Miri Make a Porno | 31452765.0 | 36851125.0 | 21240321.0 | 24000000.0 | Oct 31 2008 | R | 101.0 | Weinstein Co. | Original Screenplay | Comedy | Contemporary Fiction | Kevin Smith | 65.0 | 7.0 | 55687.0 | . 3197 Zodiac | 33080084.0 | 83080084.0 | 20983030.0 | 85000000.0 | Mar 02 2007 | R | 157.0 | Paramount Pictures | Based on Book/Short Story | Thriller/Suspense | Dramatization | David Fincher | 89.0 | NaN | NaN | . 3198 Zoom | 11989328.0 | 12506188.0 | 6679409.0 | 35000000.0 | Aug 11 2006 | PG | NaN | Sony Pictures | Based on Comic/Graphic Novel | Adventure | Super Hero | Peter Hewitt | 3.0 | 3.4 | 7424.0 | . 3199 The Legend of Zorro | 45575336.0 | 141475336.0 | NaN | 80000000.0 | Oct 28 2005 | PG | 129.0 | Sony Pictures | Remake | Adventure | Historical Fiction | Martin Campbell | 26.0 | 5.7 | 21161.0 | . 3200 The Mask of Zorro | 93828745.0 | 233700000.0 | NaN | 65000000.0 | Jul 17 1998 | PG-13 | 136.0 | Sony Pictures | Remake | Adventure | Historical Fiction | Martin Campbell | 82.0 | 6.7 | 4789.0 | . 3201 rows √ó 16 columns . Example 1: DropDown . # use specific hard-wired values as the initial selected values selection = alt.selection_single( name=&#39;Select&#39;, fields=[&#39;Major_Genre&#39;, &#39;MPAA_Rating&#39;], init={&#39;Major_Genre&#39;: &#39;Drama&#39;, &#39;MPAA_Rating&#39;: &#39;R&#39;}, bind={&#39;Major_Genre&#39;: alt.binding_select(options=genres), &#39;MPAA_Rating&#39;: alt.binding_radio(options=mpaa)} ) # scatter plot, modify opacity based on selection alt.Chart(df).mark_circle().add_selection( selection ).encode( x=&#39;Rotten_Tomatoes_Rating:Q&#39;, y=&#39;IMDB_Rating:Q&#39;, tooltip=&#39;Title:N&#39;, opacity=alt.condition(selection, alt.value(0.75), alt.value(0.05)) ) . Example 2: Tooltips . alt.Chart(df).mark_circle().add_selection( alt.selection_interval(bind=&#39;scales&#39;, encodings=[&#39;x&#39;]) ).encode( alt.X(&#39;Rotten_Tomatoes_Rating&#39;, type=&#39;quantitative&#39;), alt.Y(&#39;IMDB_Rating&#39;, type=&#39;quantitative&#39;, axis=alt.Axis(minExtent=30)), # y=alt.Y(&#39;IMDB_Rating:Q&#39;, ), # use min extent to stabilize axis title placement tooltip=[&#39;Title:N&#39;, &#39;Release_Date:N&#39;, &#39;IMDB_Rating:Q&#39;, &#39;Rotten_Tomatoes_Rating:Q&#39;] ).properties( width=500, height=400 ) . Example 3: More Tooltips . label = alt.selection_single( encodings=[&#39;x&#39;], # limit selection to x-axis value on=&#39;mouseover&#39;, # select on mouseover events nearest=True, # select data point nearest the cursor empty=&#39;none&#39; # empty selection includes no data points ) # define our base line chart of stock prices base = alt.Chart().mark_line().encode( alt.X(&#39;date:T&#39;), alt.Y(&#39;price:Q&#39;, scale=alt.Scale(type=&#39;log&#39;)), alt.Color(&#39;symbol:N&#39;) ) alt.layer( base, # base line chart # add a rule mark to serve as a guide line alt.Chart().mark_rule(color=&#39;#aaa&#39;).encode( x=&#39;date:T&#39; ).transform_filter(label), # add circle marks for selected time points, hide unselected points base.mark_circle().encode( opacity=alt.condition(label, alt.value(1), alt.value(0)) ).add_selection(label), # add white stroked text to provide a legible background for labels base.mark_text(align=&#39;left&#39;, dx=5, dy=-5, stroke=&#39;white&#39;, strokeWidth=2).encode( text=&#39;price:Q&#39; ).transform_filter(label), # add text labels for stock prices base.mark_text(align=&#39;left&#39;, dx=5, dy=-5).encode( text=&#39;price:Q&#39; ).transform_filter(label), data=stocks ).properties( width=500, height=400 ) . Data Tables . You can display tables per the usual way in your blog: . df[[&#39;Title&#39;, &#39;Worldwide_Gross&#39;, &#39;Production_Budget&#39;, &#39;Distributor&#39;, &#39;MPAA_Rating&#39;, &#39;IMDB_Rating&#39;, &#39;Rotten_Tomatoes_Rating&#39;]].head() . Title Worldwide_Gross Production_Budget Distributor MPAA_Rating IMDB_Rating Rotten_Tomatoes_Rating . 0 The Land Girls | 146083.0 | 8000000.0 | Gramercy | R | 6.1 | NaN | . 1 First Love, Last Rites | 10876.0 | 300000.0 | Strand | R | 6.9 | NaN | . 2 I Married a Strange Person | 203134.0 | 250000.0 | Lionsgate | None | 6.8 | NaN | . 3 Let&#39;s Talk About Sex | 373615.0 | 300000.0 | Fine Line | None | NaN | 13.0 | . 4 Slam | 1087521.0 | 1000000.0 | Trimark | R | 3.4 | 62.0 | . Images . Local Images . You can reference local images and they will be copied and rendered on your blog automatically. You can include these with the following markdown syntax: . ![](my_icons/fastai_logo.png) . . Remote Images . Remote images can be included with the following markdown syntax: . ![](https://image.flaticon.com/icons/svg/36/36686.svg) . . Animated Gifs . Animated Gifs work, too! . ![](https://upload.wikimedia.org/wikipedia/commons/7/71/ChessPawnSpecialMoves.gif) . . Captions . You can include captions with markdown images like this: . ![](https://www.fast.ai/images/fastai_paper/show_batch.png &quot;Credit: https://www.fast.ai/2020/02/13/fastai-A-Layered-API-for-Deep-Learning/&quot;) . . Other Elements . GitHub Flavored Emojis . Typing I give this post two :+1:! will render this: . I give this post two :+1:! . Tweetcards . Typing &gt; twitter: https://twitter.com/jakevdp/status/1204765621767901185?s=20 will render this: Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 . Youtube Videos . Typing &gt; youtube: https://youtu.be/XfoYk_Z5AkI will render this: . Boxes / Callouts . Typing &gt; Warning: There will be no second warning! will render this: . Warning: There will be no second warning! . Typing &gt; Important: Pay attention! It&#39;s important. will render this: . Important: Pay attention! It&#8217;s important. . Typing &gt; Tip: This is my tip. will render this: . Tip: This is my tip. . Typing &gt; Note: Take note of this. will render this: . Note: Take note of this. . Typing &gt; Note: A doc link to [an example website: fast.ai](https://www.fast.ai/) should also work fine. will render in the docs: . Note: A doc link to an example website: fast.ai should also work fine. . Footnotes . You can have footnotes in notebooks, however the syntax is different compared to markdown documents. This guide provides more detail about this syntax, which looks like this: . For example, here is a footnote {% fn 1 %}. And another {% fn 2 %} {{ &#39;This is the footnote.&#39; | fndetail: 1 }} {{ &#39;This is the other footnote. You can even have a [link](www.github.com)!&#39; | fndetail: 2 }} . For example, here is a footnote 1. . And another 2 . 1. This is the footnote.‚Ü© . 2. This is the other footnote. You can even have a link!‚Ü© .",
            "url": "https://shawn0918.github.io/Movie-tags-extraction-with-LDA-model/jupyter/2020/02/20/test.html",
            "relUrl": "/jupyter/2020/02/20/test.html",
            "date": " ‚Ä¢ Feb 20, 2020"
        }
        
    
  
    
        ,"post2": {
            "title": "An Example Markdown Post",
            "content": "Example Markdown Post . Basic setup . Jekyll requires blog post files to be named according to the following format: . YEAR-MONTH-DAY-filename.md . Where YEAR is a four-digit number, MONTH and DAY are both two-digit numbers, and filename is whatever file name you choose, to remind yourself what this post is about. .md is the file extension for markdown files. . The first line of the file should start with a single hash character, then a space, then your title. This is how you create a ‚Äúlevel 1 heading‚Äù in markdown. Then you can create level 2, 3, etc headings as you wish but repeating the hash character, such as you see in the line ## File names above. . Basic formatting . You can use italics, bold, code font text, and create links. Here‚Äôs a footnote 1. Here‚Äôs a horizontal rule: . . Lists . Here‚Äôs a list: . item 1 | item 2 | . And a numbered list: . item 1 | item 2 | Boxes and stuff . This is a quotation . . You can include alert boxes ‚Ä¶and‚Ä¶ . . You can include info boxes Images . . Code . You can format text and code per usual . General preformatted text: . # Do a thing do_thing() . Python code and output: . # Prints &#39;2&#39; print(1+1) . 2 . Formatting text as shell commands: . echo &quot;hello world&quot; ./some_script.sh --option &quot;value&quot; wget https://example.com/cat_photo1.png . Formatting text as YAML: . key: value - another_key: &quot;another value&quot; . Tables . Column 1 Column 2 . A thing | Another thing | . Tweetcards . Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 Footnotes . This is the footnote.¬†&#8617; . |",
            "url": "https://shawn0918.github.io/Movie-tags-extraction-with-LDA-model/markdown/2020/01/14/test-markdown-post.html",
            "relUrl": "/markdown/2020/01/14/test-markdown-post.html",
            "date": " ‚Ä¢ Jan 14, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "This website is powered by fastpages 1. . a blogging platform that natively supports Jupyter notebooks in addition to other formats.¬†&#8617; . |",
          "url": "https://shawn0918.github.io/Movie-tags-extraction-with-LDA-model/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ ‚Äúsitemap.xml‚Äù | absolute_url }} | .",
          "url": "https://shawn0918.github.io/Movie-tags-extraction-with-LDA-model/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}